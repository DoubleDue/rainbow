# LOCAL or SPARK, if LOCAL is used, the jar-ball contains
# this method must be run by hadoop -jar command so that the correct hadoop
# Configuration can be get and used to read files on HDFS.
method=SPARK

#the hostname of spark master if method=SPARK
master=localhost

# the path of ordered table directory on HDFS,
# should have the hdfs://namenode:port prefix
ordered.table.dir=/tmp/ordered/table/dir

# the path of unordered table directory on HDFS,
# should have the hdfs://namenode:port prefix
table.dir=/tmp/table/dir

# the file path of workload file
workload.file=/tmp/workload.txt

# the local directory used to write evaluation results, must end with '/'
log.dir=/tmp/log/dir

# true or false, whether or not drop file cache on each node in the cluster
drop.cache=true

# the file path of drop_caches.sh
drop.caches.sh=/tmp/drop_caches.sh